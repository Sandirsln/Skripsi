{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8aefafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "  X_train: (1149, 50, 6)\n",
      "  X_val  : (285, 50, 6)\n",
      "  X_test : (357, 50, 6)\n",
      "Input dim: 300, Classes: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              â”‚         \u001b[38;5;34m2,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚            \u001b[38;5;34m27\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,435</span> (9.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,435\u001b[0m (9.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,435</span> (9.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,435\u001b[0m (9.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3640 - loss: 25.0682   \n",
      "Epoch 1: val_loss improved from inf to 28.10881, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3571 - loss: 25.2636 - val_accuracy: 0.2807 - val_loss: 28.1088\n",
      "Epoch 2/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3439 - loss: 18.8866 \n",
      "Epoch 2: val_loss improved from 28.10881 to 22.18529, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3442 - loss: 18.7687 - val_accuracy: 0.3018 - val_loss: 22.1853\n",
      "Epoch 3/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5312 - loss: 18.4538\n",
      "Epoch 3: val_loss improved from 22.18529 to 17.72155, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4273 - loss: 11.7243 - val_accuracy: 0.3895 - val_loss: 17.7215\n",
      "Epoch 4/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5008 - loss: 6.9426 \n",
      "Epoch 4: val_loss improved from 17.72155 to 14.61645, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5005 - loss: 6.9960 - val_accuracy: 0.4281 - val_loss: 14.6165\n",
      "Epoch 5/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5438 - loss: 6.4051 \n",
      "Epoch 5: val_loss improved from 14.61645 to 12.28118, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5465 - loss: 6.2718 - val_accuracy: 0.4596 - val_loss: 12.2812\n",
      "Epoch 6/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 4.4211 \n",
      "Epoch 6: val_loss improved from 12.28118 to 10.76418, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6147 - loss: 4.3991 - val_accuracy: 0.4772 - val_loss: 10.7642\n",
      "Epoch 7/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6282 - loss: 3.2718 \n",
      "Epoch 7: val_loss improved from 10.76418 to 9.71377, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6310 - loss: 3.2665 - val_accuracy: 0.5053 - val_loss: 9.7138\n",
      "Epoch 8/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7812 - loss: 1.8851\n",
      "Epoch 8: val_loss improved from 9.71377 to 9.08037, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6634 - loss: 2.6304 - val_accuracy: 0.5263 - val_loss: 9.0804\n",
      "Epoch 9/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 2.1590 \n",
      "Epoch 9: val_loss improved from 9.08037 to 8.53660, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6959 - loss: 2.1255 - val_accuracy: 0.5368 - val_loss: 8.5366\n",
      "Epoch 10/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7125 - loss: 1.7373 \n",
      "Epoch 10: val_loss improved from 8.53660 to 8.09484, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7115 - loss: 1.6998 - val_accuracy: 0.5719 - val_loss: 8.0948\n",
      "Epoch 11/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 1.3505 \n",
      "Epoch 11: val_loss improved from 8.09484 to 7.65414, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7419 - loss: 1.3466 - val_accuracy: 0.5754 - val_loss: 7.6541\n",
      "Epoch 12/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6562 - loss: 2.4316\n",
      "Epoch 12: val_loss improved from 7.65414 to 7.43694, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7363 - loss: 1.1031 - val_accuracy: 0.5930 - val_loss: 7.4369\n",
      "Epoch 13/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8125 - loss: 0.3850\n",
      "Epoch 13: val_loss improved from 7.43694 to 7.21503, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7569 - loss: 0.8762 - val_accuracy: 0.6035 - val_loss: 7.2150\n",
      "Epoch 14/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7620 - loss: 0.8027 \n",
      "Epoch 14: val_loss improved from 7.21503 to 6.99458, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7621 - loss: 0.8022 - val_accuracy: 0.6000 - val_loss: 6.9946\n",
      "Epoch 15/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7838 - loss: 0.6534 \n",
      "Epoch 15: val_loss improved from 6.99458 to 6.84789, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 0.6566 - val_accuracy: 0.6035 - val_loss: 6.8479\n",
      "Epoch 16/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.6267 \n",
      "Epoch 16: val_loss improved from 6.84789 to 6.74445, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.6245 - val_accuracy: 0.6070 - val_loss: 6.7444\n",
      "Epoch 17/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4898 \n",
      "Epoch 17: val_loss improved from 6.74445 to 6.61403, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.4928 - val_accuracy: 0.6140 - val_loss: 6.6140\n",
      "Epoch 18/200\n",
      "\u001b[1m17/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.4572 \n",
      "Epoch 18: val_loss improved from 6.61403 to 6.49419, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8059 - loss: 0.4573 - val_accuracy: 0.6105 - val_loss: 6.4942\n",
      "Epoch 19/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.3814 \n",
      "Epoch 19: val_loss improved from 6.49419 to 6.46381, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.3899 - val_accuracy: 0.6105 - val_loss: 6.4638\n",
      "Epoch 20/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8104 - loss: 0.3867 \n",
      "Epoch 20: val_loss improved from 6.46381 to 6.33504, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.3859 - val_accuracy: 0.6140 - val_loss: 6.3350\n",
      "Epoch 21/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.3348 \n",
      "Epoch 21: val_loss did not improve from 6.33504\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.3360 - val_accuracy: 0.6211 - val_loss: 6.3944\n",
      "Epoch 22/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.3423 \n",
      "Epoch 22: val_loss did not improve from 6.33504\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.3407 - val_accuracy: 0.6491 - val_loss: 6.3697\n",
      "Epoch 23/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.3193 \n",
      "Epoch 23: val_loss did not improve from 6.33504\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.3191 - val_accuracy: 0.6526 - val_loss: 6.3847\n",
      "Epoch 24/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.2800 \n",
      "Epoch 24: val_loss improved from 6.33504 to 6.33066, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8830 - loss: 0.2812 - val_accuracy: 0.6561 - val_loss: 6.3307\n",
      "Epoch 25/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.2871 \n",
      "Epoch 25: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8743 - loss: 0.2869 - val_accuracy: 0.6702 - val_loss: 6.3498\n",
      "Epoch 26/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8660 - loss: 0.2861 \n",
      "Epoch 26: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.2830 - val_accuracy: 0.6702 - val_loss: 6.3793\n",
      "Epoch 27/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.2444 \n",
      "Epoch 27: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8934 - loss: 0.2468 - val_accuracy: 0.6702 - val_loss: 6.4081\n",
      "Epoch 28/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.2640 \n",
      "Epoch 28: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8941 - loss: 0.2609 - val_accuracy: 0.6702 - val_loss: 6.4180\n",
      "Epoch 29/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.2555 \n",
      "Epoch 29: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8922 - loss: 0.2539 - val_accuracy: 0.6702 - val_loss: 6.4518\n",
      "Epoch 30/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.2186 \n",
      "Epoch 30: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.2197 - val_accuracy: 0.6702 - val_loss: 6.4429\n",
      "Epoch 31/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2120 \n",
      "Epoch 31: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9108 - loss: 0.2127 - val_accuracy: 0.6667 - val_loss: 6.4769\n",
      "Epoch 32/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.2181 \n",
      "Epoch 32: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.2181 - val_accuracy: 0.6596 - val_loss: 6.4704\n",
      "Epoch 33/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8750 - loss: 0.1982\n",
      "Epoch 33: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.2101 - val_accuracy: 0.6596 - val_loss: 6.4612\n",
      "Epoch 34/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2109 \n",
      "Epoch 34: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9065 - loss: 0.2110 - val_accuracy: 0.6632 - val_loss: 6.4830\n",
      "Epoch 35/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2017 \n",
      "Epoch 35: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2019 - val_accuracy: 0.6632 - val_loss: 6.4834\n",
      "Epoch 36/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.1972 \n",
      "Epoch 36: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9105 - loss: 0.1980 - val_accuracy: 0.6632 - val_loss: 6.4786\n",
      "Epoch 37/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.1741 \n",
      "Epoch 37: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9201 - loss: 0.1785 - val_accuracy: 0.6632 - val_loss: 6.4838\n",
      "Epoch 38/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.1817 \n",
      "Epoch 38: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9172 - loss: 0.1846 - val_accuracy: 0.6632 - val_loss: 6.4716\n",
      "Epoch 39/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.1823 \n",
      "Epoch 39: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.1828 - val_accuracy: 0.6632 - val_loss: 6.4635\n",
      "Epoch 40/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.1845 \n",
      "Epoch 40: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.1846 - val_accuracy: 0.6632 - val_loss: 6.4631\n",
      "Epoch 41/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.1879 \n",
      "Epoch 41: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.1870 - val_accuracy: 0.6632 - val_loss: 6.4734\n",
      "Epoch 42/200\n",
      "\u001b[1m28/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.1575 \n",
      "Epoch 42: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.1638 - val_accuracy: 0.6561 - val_loss: 6.4683\n",
      "Epoch 43/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9375 - loss: 0.1665\n",
      "Epoch 43: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.1852 - val_accuracy: 0.6596 - val_loss: 6.4606\n",
      "Epoch 44/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.2052 \n",
      "Epoch 44: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8985 - loss: 0.2017 - val_accuracy: 0.6596 - val_loss: 6.4578\n",
      "Epoch 45/200\n",
      "\u001b[1m27/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9018 - loss: 0.1754 \n",
      "Epoch 45: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.1730 - val_accuracy: 0.6596 - val_loss: 6.4623\n",
      "Epoch 46/200\n",
      "\u001b[1m15/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.1236 \n",
      "Epoch 46: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.1480 - val_accuracy: 0.6596 - val_loss: 6.4543\n",
      "Epoch 47/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.1570 \n",
      "Epoch 47: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.1579 - val_accuracy: 0.6596 - val_loss: 6.4386\n",
      "Epoch 48/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.1526 \n",
      "Epoch 48: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9156 - loss: 0.1530 - val_accuracy: 0.6596 - val_loss: 6.4301\n",
      "Epoch 49/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.1497 \n",
      "Epoch 49: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9223 - loss: 0.1511 - val_accuracy: 0.6561 - val_loss: 6.4588\n",
      "Epoch 50/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.1586 \n",
      "Epoch 50: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9180 - loss: 0.1578 - val_accuracy: 0.6561 - val_loss: 6.4595\n",
      "Epoch 51/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.1341\n",
      "Epoch 51: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9302 - loss: 0.1380 - val_accuracy: 0.6561 - val_loss: 6.4719\n",
      "Epoch 52/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.1605 \n",
      "Epoch 52: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9163 - loss: 0.1589 - val_accuracy: 0.6561 - val_loss: 6.4603\n",
      "Epoch 53/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.1563 \n",
      "Epoch 53: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.1554 - val_accuracy: 0.6526 - val_loss: 6.4260\n",
      "Epoch 54/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.1470 \n",
      "Epoch 54: val_loss did not improve from 6.33066\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9196 - loss: 0.1469 - val_accuracy: 0.6526 - val_loss: 6.4389\n",
      "\n",
      "âœ… Akurasi test: 67.23%\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      "ğŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7041    1.0000    0.8264       119\n",
      "           1     0.5667    0.5714    0.5690       119\n",
      "           2     0.7794    0.4454    0.5668       119\n",
      "\n",
      "    accuracy                         0.6723       357\n",
      "   macro avg     0.6834    0.6723    0.6541       357\n",
      "weighted avg     0.6834    0.6723    0.6541       357\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[119   0   0]\n",
      " [ 36  68  15]\n",
      " [ 14  52  53]]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\muham\\AppData\\Local\\Temp\\tmp95nor38i\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\muham\\AppData\\Local\\Temp\\tmp95nor38i\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\muham\\AppData\\Local\\Temp\\tmp95nor38i'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 300), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1588810983632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588810984400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588810982672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588810985552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "\n",
      "âœ… Model terbaik disimpan sebagai:\n",
      " - best_mlp8_model.keras  (callback terbaik)\n",
      " - mlp_8neuron_model.tflite (untuk ESP32)\n"
     ]
    }
   ],
   "source": [
    "# 04_train_mlp_8neuron_metrics.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# === 1. Load dataset hasil windowing ===\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "X_val   = np.load(\"X_val.npy\")\n",
    "y_val   = np.load(\"y_val.npy\")\n",
    "X_test  = np.load(\"X_test.npy\")\n",
    "y_test  = np.load(\"y_test.npy\")\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"  X_train:\", X_train.shape)\n",
    "print(\"  X_val  :\", X_val.shape)\n",
    "print(\"  X_test :\", X_test.shape)\n",
    "\n",
    "# === 2. Normalisasi (optional tapi disarankan) ===\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_val   = X_val.astype(\"float32\")\n",
    "X_test  = X_test.astype(\"float32\")\n",
    "\n",
    "# === 3. Flatten input (karena MLP butuh 1D vector) ===\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val   = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test  = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input dim: {input_dim}, Classes: {num_classes}\")\n",
    "\n",
    "# === 4. Bangun model MLP (1 hidden layer, 8 neuron) ===\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Optimizer Adam dengan lr 0.001\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# === 5. Siapkan callbacks ===\n",
    "cb_earlystop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "cb_checkpoint = callbacks.ModelCheckpoint(\n",
    "    filepath='best_mlp8_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "callbacks_list = [cb_earlystop, cb_checkpoint]\n",
    "\n",
    "# === 6. Latih model ===\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,             # biarkan besar, early stopping akan hentikan otomatis\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === 7. Evaluasi model terbaik di test set ===\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nâœ… Akurasi test: {test_acc*100:.2f}%\")\n",
    "\n",
    "# === 8. Prediksi untuk metrik tambahan ===\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Buat laporan metrik klasifikasi\n",
    "print(\"\\nğŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# Confusion matrix opsional\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "# === 9. Simpan model final & versi TFLite ===\n",
    "model.save(\"mlp_8neuron_final.keras\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "with open(\"mlp_8neuron_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"\\nâœ… Model terbaik disimpan sebagai:\")\n",
    "print(\" - best_mlp8_model.keras  (callback terbaik)\")\n",
    "print(\" - mlp_8neuron_model.tflite (untuk ESP32)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a2e6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (1149, 50, 6) (285, 50, 6) (357, 50, 6)\n",
      "Train means : [ 0.2645  0.0078  1.0119 -3.4102  0.6024 -2.5877]\n",
      "Train stds  : [ 0.5355  0.3022  0.5587 35.4983 64.2229 41.9884]\n",
      "Input dim=300, classes=3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,408</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚         \u001b[38;5;34m1,200\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              â”‚         \u001b[38;5;34m2,408\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚            \u001b[38;5;34m27\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,635</span> (14.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,635\u001b[0m (14.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,035</span> (11.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,035\u001b[0m (11.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> (2.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m600\u001b[0m (2.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m27s\u001b[0m 799ms/step - accuracy: 0.4688 - loss: 1.4069\n",
      "Epoch 1: val_loss improved from inf to 1.17322, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3737 - loss: 1.3789 - val_accuracy: 0.5228 - val_loss: 1.1732\n",
      "Epoch 2/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3750 - loss: 1.1533\n",
      "Epoch 2: val_loss improved from 1.17322 to 0.93819, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5602 - loss: 0.9929 - val_accuracy: 0.6035 - val_loss: 0.9382\n",
      "Epoch 3/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8125 - loss: 0.6339\n",
      "Epoch 3: val_loss improved from 0.93819 to 0.79282, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6961 - loss: 0.7379 - val_accuracy: 0.6561 - val_loss: 0.7928\n",
      "Epoch 4/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6875 - loss: 0.6241\n",
      "Epoch 4: val_loss improved from 0.79282 to 0.70327, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7027 - loss: 0.6333 - val_accuracy: 0.7158 - val_loss: 0.7033\n",
      "Epoch 5/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6562 - loss: 0.5868\n",
      "Epoch 5: val_loss improved from 0.70327 to 0.64213, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7501 - loss: 0.5594 - val_accuracy: 0.7579 - val_loss: 0.6421\n",
      "Epoch 6/300\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8362 - loss: 0.4414 \n",
      "Epoch 6: val_loss improved from 0.64213 to 0.58939, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.4411 - val_accuracy: 0.7895 - val_loss: 0.5894\n",
      "Epoch 7/300\n",
      "\u001b[1m32/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.3774 \n",
      "Epoch 7: val_loss improved from 0.58939 to 0.55432, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8884 - loss: 0.3756 - val_accuracy: 0.8035 - val_loss: 0.5543\n",
      "Epoch 8/300\n",
      "\u001b[1m34/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.3227 \n",
      "Epoch 8: val_loss improved from 0.55432 to 0.52678, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.3221 - val_accuracy: 0.8070 - val_loss: 0.5268\n",
      "Epoch 9/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.9062 - loss: 0.3042\n",
      "Epoch 9: val_loss improved from 0.52678 to 0.50126, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.2648 - val_accuracy: 0.8281 - val_loss: 0.5013\n",
      "Epoch 10/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.1563\n",
      "Epoch 10: val_loss improved from 0.50126 to 0.49156, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.2325 - val_accuracy: 0.8316 - val_loss: 0.4916\n",
      "Epoch 11/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.1633\n",
      "Epoch 11: val_loss improved from 0.49156 to 0.47330, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.2002 - val_accuracy: 0.8351 - val_loss: 0.4733\n",
      "Epoch 12/300\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.1642 \n",
      "Epoch 12: val_loss improved from 0.47330 to 0.46607, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9685 - loss: 0.1647 - val_accuracy: 0.8386 - val_loss: 0.4661\n",
      "Epoch 13/300\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.1424 \n",
      "Epoch 13: val_loss did not improve from 0.46607\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.1424 - val_accuracy: 0.8386 - val_loss: 0.4698\n",
      "Epoch 14/300\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9661 - loss: 0.1565 \n",
      "Epoch 14: val_loss improved from 0.46607 to 0.46190, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.1559 - val_accuracy: 0.8386 - val_loss: 0.4619\n",
      "Epoch 15/300\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9829 - loss: 0.1115 \n",
      "Epoch 15: val_loss improved from 0.46190 to 0.44905, saving model to best_mlp8_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.1121 - val_accuracy: 0.8456 - val_loss: 0.4490\n",
      "Epoch 16/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9375 - loss: 0.1132\n",
      "Epoch 16: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.1086 - val_accuracy: 0.8491 - val_loss: 0.4583\n",
      "Epoch 17/300\n",
      "\u001b[1m33/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0961 \n",
      "Epoch 17: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0968 - val_accuracy: 0.8456 - val_loss: 0.4719\n",
      "Epoch 18/300\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0962 \n",
      "Epoch 18: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0961 - val_accuracy: 0.8491 - val_loss: 0.4653\n",
      "Epoch 19/300\n",
      "\u001b[1m23/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.1143 \n",
      "Epoch 19: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.1062 - val_accuracy: 0.8386 - val_loss: 0.4839\n",
      "Epoch 20/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0399\n",
      "Epoch 20: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0805 - val_accuracy: 0.8596 - val_loss: 0.4650\n",
      "Epoch 21/300\n",
      "\u001b[1m33/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0700 \n",
      "Epoch 21: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0708 - val_accuracy: 0.8526 - val_loss: 0.4787\n",
      "Epoch 22/300\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0542 \n",
      "Epoch 22: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0542 - val_accuracy: 0.8596 - val_loss: 0.4650\n",
      "Epoch 23/300\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0535 \n",
      "Epoch 23: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0539 - val_accuracy: 0.8561 - val_loss: 0.4684\n",
      "Epoch 24/300\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0444 \n",
      "Epoch 24: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0455 - val_accuracy: 0.8561 - val_loss: 0.5099\n",
      "Epoch 25/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0800\n",
      "Epoch 25: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0555 - val_accuracy: 0.8526 - val_loss: 0.5005\n",
      "Epoch 26/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0532\n",
      "Epoch 26: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0515 - val_accuracy: 0.8632 - val_loss: 0.4794\n",
      "Epoch 27/300\n",
      "\u001b[1m33/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0518 \n",
      "Epoch 27: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0517 - val_accuracy: 0.8632 - val_loss: 0.4863\n",
      "Epoch 28/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0365\n",
      "Epoch 28: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0411 - val_accuracy: 0.8737 - val_loss: 0.4721\n",
      "Epoch 29/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0347\n",
      "Epoch 29: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0563 - val_accuracy: 0.8667 - val_loss: 0.4797\n",
      "Epoch 30/300\n",
      "\u001b[1m28/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0318 \n",
      "Epoch 30: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0328 - val_accuracy: 0.8632 - val_loss: 0.4916\n",
      "Epoch 31/300\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0307 \n",
      "Epoch 31: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0310 - val_accuracy: 0.8561 - val_loss: 0.5101\n",
      "Epoch 32/300\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0248\n",
      "Epoch 32: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0371 - val_accuracy: 0.8596 - val_loss: 0.5180\n",
      "Epoch 33/300\n",
      "\u001b[1m33/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0307 \n",
      "Epoch 33: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0307 - val_accuracy: 0.8737 - val_loss: 0.5028\n",
      "Epoch 34/300\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0333 \n",
      "Epoch 34: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0332 - val_accuracy: 0.8842 - val_loss: 0.4693\n",
      "Epoch 35/300\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0279 \n",
      "Epoch 35: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0284 - val_accuracy: 0.8632 - val_loss: 0.5057\n",
      "Epoch 36/300\n",
      "\u001b[1m27/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0669 \n",
      "Epoch 36: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0601 - val_accuracy: 0.8737 - val_loss: 0.4889\n",
      "Epoch 37/300\n",
      "\u001b[1m27/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0228 \n",
      "Epoch 37: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0238 - val_accuracy: 0.8632 - val_loss: 0.5275\n",
      "Epoch 38/300\n",
      "\u001b[1m28/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0214 \n",
      "Epoch 38: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0215 - val_accuracy: 0.8632 - val_loss: 0.5183\n",
      "Epoch 39/300\n",
      "\u001b[1m28/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0214 \n",
      "Epoch 39: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0216 - val_accuracy: 0.8632 - val_loss: 0.5209\n",
      "Epoch 40/300\n",
      "\u001b[1m28/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0255 \n",
      "Epoch 40: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0261 - val_accuracy: 0.8632 - val_loss: 0.5016\n",
      "Epoch 41/300\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0164 \n",
      "Epoch 41: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0167 - val_accuracy: 0.8561 - val_loss: 0.5320\n",
      "Epoch 42/300\n",
      "\u001b[1m20/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0223 \n",
      "Epoch 42: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0300 - val_accuracy: 0.8316 - val_loss: 0.6284\n",
      "Epoch 43/300\n",
      "\u001b[1m26/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0265 \n",
      "Epoch 43: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9939 - loss: 0.0280 - val_accuracy: 0.8596 - val_loss: 0.5394\n",
      "Epoch 44/300\n",
      "\u001b[1m27/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0227 \n",
      "Epoch 44: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0226 - val_accuracy: 0.8667 - val_loss: 0.5143\n",
      "Epoch 45/300\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0324 \n",
      "Epoch 45: val_loss did not improve from 0.44905\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0315 - val_accuracy: 0.8667 - val_loss: 0.5443\n",
      "\n",
      "âœ… Test accuracy: 87.39%\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\n",
      "ğŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9154    1.0000    0.9558       119\n",
      "           1     0.7770    0.9664    0.8614       119\n",
      "           2     0.9873    0.6555    0.7879       119\n",
      "\n",
      "    accuracy                         0.8739       357\n",
      "   macro avg     0.8933    0.8739    0.8684       357\n",
      "weighted avg     0.8933    0.8739    0.8684       357\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[119   0   0]\n",
      " [  3 115   1]\n",
      " [  8  33  78]]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\muham\\AppData\\Local\\Temp\\tmpho7p95fl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\muham\\AppData\\Local\\Temp\\tmpho7p95fl\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\muham\\AppData\\Local\\Temp\\tmpho7p95fl'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 300), dtype=tf.float32, name='keras_tensor_3')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1588813299792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813301520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813310352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813300560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813300368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813310544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813314768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813313424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "\n",
      "Files saved:\n",
      " - best_mlp8_model.keras\n",
      " - mlp_8neuron_final.keras\n",
      " - mlp_8neuron_model.tflite\n",
      " - scaler_stats.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 1) load windowed data =====\n",
    "X_train = np.load(\"X_train.npy\")  # (N, 50, 6)\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "X_val   = np.load(\"X_val.npy\")\n",
    "y_val   = np.load(\"y_val.npy\")\n",
    "X_test  = np.load(\"X_test.npy\")\n",
    "y_test  = np.load(\"y_test.npy\")\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# ===== 2) z-score per channel (pakai statistik TRAIN saja) =====\n",
    "def fit_channel_stats(X):  # X:(N, T, C)\n",
    "    XR = X.reshape(-1, X.shape[-1])     # (N*T, C)\n",
    "    mean = XR.mean(axis=0)\n",
    "    std  = XR.std(axis=0) + 1e-8\n",
    "    return mean, std\n",
    "\n",
    "def apply_channel_stats(X, mean, std):\n",
    "    return (X - mean) / std\n",
    "\n",
    "mean_tr, std_tr = fit_channel_stats(X_train)\n",
    "np.savez(\"scaler_stats.npz\", mean=mean_tr, std=std_tr)\n",
    "print(\"Train means :\", np.round(mean_tr, 4))\n",
    "print(\"Train stds  :\", np.round(std_tr, 4))\n",
    "\n",
    "X_train = apply_channel_stats(X_train, mean_tr, std_tr).astype(\"float32\")\n",
    "X_val   = apply_channel_stats(X_val,   mean_tr, std_tr).astype(\"float32\")\n",
    "X_test  = apply_channel_stats(X_test,  mean_tr, std_tr).astype(\"float32\")\n",
    "\n",
    "# ===== 3) flatten untuk MLP =====\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)  # (N, 300)\n",
    "X_val   = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test  = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "input_dim   = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(f\"Input dim={input_dim}, classes={num_classes}\")\n",
    "\n",
    "# ===== 4) model: 1 hidden layer (8) + BatchNorm opsional =====\n",
    "inputs = layers.Input(shape=(input_dim,))\n",
    "x = layers.BatchNormalization()(inputs)      # opsional tapi membantu\n",
    "x = layers.Dense(8, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# ===== 5) callbacks =====\n",
    "cb_early = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "cb_ckpt = callbacks.ModelCheckpoint(\n",
    "    filepath='best_mlp8_model.keras',\n",
    "    monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# ===== 6) train =====\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=300, batch_size=32,\n",
    "    callbacks=[cb_early, cb_ckpt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ===== 7) evaluate =====\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nâœ… Test accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(\"\\nğŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion matrix:\\n\", cm)\n",
    "\n",
    "# ===== 8) save final + tflite =====\n",
    "model.save(\"mlp_8neuron_final.keras\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]   # quantization-ready\n",
    "tflite = converter.convert()\n",
    "open(\"mlp_8neuron_model.tflite\", \"wb\").write(tflite)\n",
    "print(\"\\nFiles saved:\\n - best_mlp8_model.keras\\n - mlp_8neuron_final.keras\\n - mlp_8neuron_model.tflite\\n - scaler_stats.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27a5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (1149, 50, 6) (285, 50, 6) (357, 50, 6)\n",
      "Train means : [ 0.2645  0.0078  1.0119 -3.4102  0.6024 -2.5877]\n",
      "Train stds  : [ 0.5355  0.3022  0.5587 35.4983 64.2229 41.9884]\n",
      "Input dim=300, classes=3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,816</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚         \u001b[38;5;34m1,200\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚         \u001b[38;5;34m4,816\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             â”‚           \u001b[38;5;34m272\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚            \u001b[38;5;34m51\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,339</span> (24.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,339\u001b[0m (24.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,739</span> (22.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,739\u001b[0m (22.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> (2.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m600\u001b[0m (2.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4038 - loss: 1.1811   \n",
      "Epoch 1: val_loss improved from inf to 0.90046, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4083 - loss: 1.1723 - val_accuracy: 0.6526 - val_loss: 0.9005\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 0.8755\n",
      "Epoch 2: val_loss improved from 0.90046 to 0.71494, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6361 - loss: 0.8414 - val_accuracy: 0.7053 - val_loss: 0.7149\n",
      "Epoch 3/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.6158 \n",
      "Epoch 3: val_loss improved from 0.71494 to 0.57313, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.6148 - val_accuracy: 0.7509 - val_loss: 0.5731\n",
      "Epoch 4/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.5311\n",
      "Epoch 4: val_loss improved from 0.57313 to 0.46893, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.4793 - val_accuracy: 0.8456 - val_loss: 0.4689\n",
      "Epoch 5/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.3554 \n",
      "Epoch 5: val_loss improved from 0.46893 to 0.40655, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9155 - loss: 0.3550 - val_accuracy: 0.8807 - val_loss: 0.4066\n",
      "Epoch 6/200\n",
      "\u001b[1m31/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2812 \n",
      "Epoch 6: val_loss improved from 0.40655 to 0.35512, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9445 - loss: 0.2784 - val_accuracy: 0.8807 - val_loss: 0.3551\n",
      "Epoch 7/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.2299\n",
      "Epoch 7: val_loss improved from 0.35512 to 0.32449, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9575 - loss: 0.2148 - val_accuracy: 0.9018 - val_loss: 0.3245\n",
      "Epoch 8/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.1099\n",
      "Epoch 8: val_loss improved from 0.32449 to 0.32117, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.1655 - val_accuracy: 0.8842 - val_loss: 0.3212\n",
      "Epoch 9/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0971\n",
      "Epoch 9: val_loss improved from 0.32117 to 0.28875, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.1159 - val_accuracy: 0.9053 - val_loss: 0.2888\n",
      "Epoch 10/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9688 - loss: 0.1010\n",
      "Epoch 10: val_loss improved from 0.28875 to 0.27390, saving model to best_mlp2x16_model.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0909 - val_accuracy: 0.8947 - val_loss: 0.2739\n",
      "Epoch 11/200\n",
      "\u001b[1m20/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0692 \n",
      "Epoch 11: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0696 - val_accuracy: 0.8982 - val_loss: 0.2801\n",
      "Epoch 12/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0490\n",
      "Epoch 12: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0636 - val_accuracy: 0.8877 - val_loss: 0.2924\n",
      "Epoch 13/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0523 \n",
      "Epoch 13: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0518 - val_accuracy: 0.8982 - val_loss: 0.2815\n",
      "Epoch 14/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0494 \n",
      "Epoch 14: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0497 - val_accuracy: 0.8947 - val_loss: 0.2838\n",
      "Epoch 15/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0457\n",
      "Epoch 15: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0324 - val_accuracy: 0.8842 - val_loss: 0.3340\n",
      "Epoch 16/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 16: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0282 - val_accuracy: 0.9088 - val_loss: 0.2763\n",
      "Epoch 17/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0611\n",
      "Epoch 17: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0311 - val_accuracy: 0.8912 - val_loss: 0.3243\n",
      "Epoch 18/200\n",
      "\u001b[1m19/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0270 \n",
      "Epoch 18: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0282 - val_accuracy: 0.9088 - val_loss: 0.2921\n",
      "Epoch 19/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0113\n",
      "Epoch 19: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0273 - val_accuracy: 0.9123 - val_loss: 0.2870\n",
      "Epoch 20/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0243\n",
      "Epoch 20: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0191 - val_accuracy: 0.9053 - val_loss: 0.3378\n",
      "Epoch 21/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0150 \n",
      "Epoch 21: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0157 - val_accuracy: 0.9088 - val_loss: 0.3333\n",
      "Epoch 22/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 22: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0135 - val_accuracy: 0.9053 - val_loss: 0.3271\n",
      "Epoch 23/200\n",
      "\u001b[1m21/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0128 \n",
      "Epoch 23: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0180 - val_accuracy: 0.9123 - val_loss: 0.3392\n",
      "Epoch 24/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0093\n",
      "Epoch 24: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0122 - val_accuracy: 0.9228 - val_loss: 0.3297\n",
      "Epoch 25/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0059\n",
      "Epoch 25: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9053 - val_loss: 0.3597\n",
      "Epoch 26/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 26: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0148 - val_accuracy: 0.9123 - val_loss: 0.3603\n",
      "Epoch 27/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0080 \n",
      "Epoch 27: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.9158 - val_loss: 0.3418\n",
      "Epoch 28/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0086 \n",
      "Epoch 28: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0095 - val_accuracy: 0.9158 - val_loss: 0.3259\n",
      "Epoch 29/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 29: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9158 - val_loss: 0.3387\n",
      "Epoch 30/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0104 \n",
      "Epoch 30: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0105 - val_accuracy: 0.9018 - val_loss: 0.4065\n",
      "Epoch 31/200\n",
      "\u001b[1m35/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0099 \n",
      "Epoch 31: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.9158 - val_loss: 0.3514\n",
      "Epoch 32/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 32: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0472 - val_accuracy: 0.9088 - val_loss: 0.3905\n",
      "Epoch 33/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0099\n",
      "Epoch 33: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0160 - val_accuracy: 0.9018 - val_loss: 0.3593\n",
      "Epoch 34/200\n",
      "\u001b[1m33/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0061 \n",
      "Epoch 34: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8947 - val_loss: 0.3641\n",
      "Epoch 35/200\n",
      "\u001b[1m29/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0046 \n",
      "Epoch 35: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8947 - val_loss: 0.3733\n",
      "Epoch 36/200\n",
      "\u001b[1m22/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0050 \n",
      "Epoch 36: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0054 - val_accuracy: 0.8947 - val_loss: 0.4128\n",
      "Epoch 37/200\n",
      "\u001b[1m 1/36\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 37: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8947 - val_loss: 0.4016\n",
      "Epoch 38/200\n",
      "\u001b[1m30/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9962 - loss: 0.0117 \n",
      "Epoch 38: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0115 - val_accuracy: 0.9053 - val_loss: 0.4255\n",
      "Epoch 39/200\n",
      "\u001b[1m34/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0070 \n",
      "Epoch 39: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0071 - val_accuracy: 0.8982 - val_loss: 0.4238\n",
      "Epoch 40/200\n",
      "\u001b[1m32/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0062 \n",
      "Epoch 40: val_loss did not improve from 0.27390\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0061 - val_accuracy: 0.9158 - val_loss: 0.3366\n",
      "\n",
      "âœ… Test accuracy: 87.39%\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      "ğŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9370    1.0000    0.9675       119\n",
      "           1     0.7603    0.9328    0.8377       119\n",
      "           2     0.9762    0.6891    0.8079       119\n",
      "\n",
      "    accuracy                         0.8739       357\n",
      "   macro avg     0.8912    0.8739    0.8710       357\n",
      "weighted avg     0.8912    0.8739    0.8710       357\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[119   0   0]\n",
      " [  6 111   2]\n",
      " [  2  35  82]]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\muham\\AppData\\Local\\Temp\\tmpifnxbyrk\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\muham\\AppData\\Local\\Temp\\tmpifnxbyrk\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\muham\\AppData\\Local\\Temp\\tmpifnxbyrk'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 300), dtype=tf.float32, name='keras_tensor_7')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1588813733840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813737872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813734416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813735952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813736912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813732688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813735184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813728080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813738064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1588813729808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "\n",
      "Files saved:\n",
      " - best_mlp2x16_model.keras  (callback best)\n",
      " - mlp_2layer16_final.keras  (final model)\n",
      " - mlp_2layer16_model.tflite (for ESP32)\n",
      " - scaler_stats.npz          (normalization stats)\n"
     ]
    }
   ],
   "source": [
    "# 04_train_mlp_2layer16_metrics_norm.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ===== 1) Load windowed data =====\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "X_val   = np.load(\"X_val.npy\")\n",
    "y_val   = np.load(\"y_val.npy\")\n",
    "X_test  = np.load(\"X_test.npy\")\n",
    "y_test  = np.load(\"y_test.npy\")\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# ===== 2) Z-score per channel (pakai statistik TRAIN saja) =====\n",
    "def fit_channel_stats(X):\n",
    "    XR = X.reshape(-1, X.shape[-1])  # (N*T, C)\n",
    "    mean = XR.mean(axis=0)\n",
    "    std = XR.std(axis=0) + 1e-8\n",
    "    return mean, std\n",
    "\n",
    "def apply_channel_stats(X, mean, std):\n",
    "    return (X - mean) / std\n",
    "\n",
    "mean_tr, std_tr = fit_channel_stats(X_train)\n",
    "np.savez(\"scaler_stats.npz\", mean=mean_tr, std=std_tr)\n",
    "print(\"Train means :\", np.round(mean_tr, 4))\n",
    "print(\"Train stds  :\", np.round(std_tr, 4))\n",
    "\n",
    "X_train = apply_channel_stats(X_train, mean_tr, std_tr).astype(\"float32\")\n",
    "X_val   = apply_channel_stats(X_val,   mean_tr, std_tr).astype(\"float32\")\n",
    "X_test  = apply_channel_stats(X_test,  mean_tr, std_tr).astype(\"float32\")\n",
    "\n",
    "# ===== 3) Flatten untuk MLP =====\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val   = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test  = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(f\"Input dim={input_dim}, classes={num_classes}\")\n",
    "\n",
    "# ===== 4) Model: 2 hidden layer, 16 neuron per layer =====\n",
    "inputs = layers.Input(shape=(input_dim,))\n",
    "x = layers.BatchNormalization()(inputs)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "# ===== 5) Compile =====\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ===== 6) Callbacks =====\n",
    "cb_early = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "cb_ckpt = callbacks.ModelCheckpoint(\n",
    "    filepath='best_mlp2x16_model.keras',\n",
    "    monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# ===== 7) Training =====\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[cb_early, cb_ckpt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ===== 8) Evaluation =====\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nâœ… Test accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(\"\\nğŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion matrix:\\n\", cm)\n",
    "\n",
    "# ===== 9) Save final model + TFLite =====\n",
    "model.save(\"mlp_2layer16_final.keras\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]   # quantization-ready\n",
    "tflite_model = converter.convert()\n",
    "open(\"mlp_2layer16_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\" - best_mlp2x16_model.keras  (callback best)\")\n",
    "print(\" - mlp_2layer16_final.keras  (final model)\")\n",
    "print(\" - mlp_2layer16_model.tflite (for ESP32)\")\n",
    "print(\" - scaler_stats.npz          (normalization stats)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
